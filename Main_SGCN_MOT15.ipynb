{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision&Perception Project\n",
    "# SGCN:Sparse Graph Convolution Network for Pedestrian Trajectory Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LWASlTkEvUzz"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "import glob\n",
    "import copy\n",
    "import pickle\n",
    "import argparse\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import datetime\n",
    "\n",
    "from utils import *\n",
    "from model import *\n",
    "from metrics import *\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Settings\n",
    "### 2.1 Setting GPU training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y9-chkI6vUz5",
    "outputId": "a5647554-1d65-43fc-829a-aaa59fe96547"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version:  2.3.0\n",
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.context._EagerDeviceContext at 0x222d0c2c780>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Tensorflow Version: ', tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.device('/device:GPU:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Setting Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7APKPn1cvUz6",
    "outputId": "b5027124-dfb4-4ea6-a379-e889b55f971f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training initiating....\n",
      "Namespace(batch_size=128, clip_grad=10, dataset='data', gpu_num='0', lr=0.001, lr_sh_rate=100, milestones=[50, 100], momentum=0.9, num_epochs=20, obs_len=8, pred_len=12, tag='sgcn', use_lrschd=True, weight_decay=0.0001)\n"
     ]
    }
   ],
   "source": [
    "# Setting parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--obs_len', type=int, default=8)\n",
    "parser.add_argument('--pred_len', type=int, default=12)\n",
    "parser.add_argument('--dataset', default='data', help='eth,hotel,univ,zara1,zara2')\n",
    "# Training specifc parameters\n",
    "parser.add_argument('--batch_size', type=int, default=128, help='minibatch size')\n",
    "parser.add_argument('--num_epochs', type=int, default=20, help='number of epochs')\n",
    "parser.add_argument('--clip_grad', type=float, default=10, help='gadient clipping')\n",
    "parser.add_argument('--lr', type=float, default=0.001, help='learning rate')\n",
    "parser.add_argument('--momentum', type=float, default=0.9, help='momentum of lr')\n",
    "parser.add_argument('--weight_decay', type=float, default=0.0001, help='weight_decay on l2 reg')\n",
    "parser.add_argument('--lr_sh_rate', type=int, default=100, help='number of steps to drop the lr')\n",
    "parser.add_argument('--milestones', type=int, default=[50, 100], help='number of steps to drop the lr')\n",
    "parser.add_argument('--use_lrschd', action=\"store_true\", default=True, help='Use lr rate scheduler')\n",
    "parser.add_argument('--tag', default='sgcn', help='personal tag for the model ')\n",
    "parser.add_argument('--gpu_num', default=\"0\", type=str)\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "print(\"Training initiating....\")\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Setting Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xKNemHWuvUz7"
   },
   "outputs": [],
   "source": [
    "# computing loss\n",
    "def graph_loss(V_pred, V_target):\n",
    "    return bivariate_loss(V_pred, V_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading Training & Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QeIVfNfT2qIc",
    "outputId": "43b38c16-2c18-4bca-d227-7bee5dae5f4b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████████████████▏                                                      | 934/3244 [00:00<00:00, 9335.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Data .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3244/3244 [00:00<00:00, 8383.92it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 895/895 [00:00<00:00, 11053.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Data .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "obs_seq_len = args.obs_len                        # obs_len=8\n",
    "pred_seq_len = args.pred_len                      # pred_len=12\n",
    "data_set = './dataset/data/'\n",
    "\n",
    "# Loading training data\n",
    "dset_train = TrajectoryDataset(\n",
    "    data_set + 'train1/',\n",
    "    obs_len=obs_seq_len,\n",
    "    pred_len=pred_seq_len,\n",
    "    skip=1)\n",
    "loader_train = np.asarray(dset_train)\n",
    "\n",
    "# Loading validation data\n",
    "dset_val = TrajectoryDataset(\n",
    "    data_set + 'valid1/',\n",
    "    obs_len=obs_seq_len,\n",
    "    pred_len=pred_seq_len,\n",
    "    skip=1)\n",
    "loader_val = np.asarray(dset_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preparing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Specifying GPU Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5_QD6900vUz9",
    "outputId": "44fed17b-4346-4609-c890-bb21a2cfac0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started ...\n"
     ]
    }
   ],
   "source": [
    "print('Training started ...')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Instantiating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "g3xYQuYBvUz9"
   },
   "outputs": [],
   "source": [
    "model = TrajectoryModel(number_asymmetric_conv_layer=7, embedding_dims=64, number_gcn_layers=1, dropout=0,\n",
    "                        obs_len=8, pred_len=12, n_tcn=5, out_dims=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Initializing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "id": "yiW43jv1vUz-",
    "outputId": "2ac306f9-9a18-43a9-89be-1b09012f2e78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer trajectory_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer softmax is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer softmax_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.get_logger().setLevel('INFO')\n",
    "for cnt, batch in enumerate(loader_train):\n",
    "    obs_traj, pred_traj_gt, obs_traj_rel, pred_traj_gt_rel, non_linear_ped, loss_mask, V_obs, V_tr = batch\n",
    "    V_obs = V_obs[np.newaxis, :]\n",
    "    identity_spatial = tf.ones((V_obs.shape[1], V_obs.shape[2], V_obs.shape[2])) * tf.eye(V_obs.shape[2])  # [obs_len N N]\n",
    "    identity_temporal = tf.ones((V_obs.shape[2], V_obs.shape[1], V_obs.shape[1])) * tf.eye(V_obs.shape[1])  # [N obs_len obs_len]\n",
    "    identity = np.array([identity_spatial, identity_temporal])\n",
    "    V_pred = model(V_obs, identity)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Initializing Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-ftR1MDEvU0A"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Using Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "s_aD0OpQ5yao"
   },
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
    "valid_log_dir = 'logs/gradient_tape/' + current_time + '/valid'\n",
    "test_log_dir = 'logs/gradient_tape/' + current_time + '/test'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
    "valid_summary_writer = tf.summary.create_file_writer(valid_log_dir)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean('Train Loss', dtype=tf.float32)\n",
    "valid_loss = tf.keras.metrics.Mean('Valid Loss', dtype=tf.float32)\n",
    "ADE_loss = tf.keras.metrics.Mean('ADE', dtype=tf.float32)\n",
    "FDE_loss = tf.keras.metrics.Mean('FDE', dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Defining Train, Valid & Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "47tnKhIYvU0A"
   },
   "outputs": [],
   "source": [
    "def train(epoch, model, optimizer, loader_train):\n",
    "    global metrics, constant_metrics\n",
    "    \n",
    "    batch_count = 0\n",
    "    is_fst_loss = True\n",
    "    flag = False\n",
    "    loader_len = len(loader_train)\n",
    "    turn_point = int(loader_len / args.batch_size) * args.batch_size + loader_len % args.batch_size - 1\n",
    "    \n",
    "    loss_sum_list = []\n",
    "    V_obs_list = []\n",
    "    V_tr_list = []\n",
    "    identity_list = []\n",
    "    \n",
    "    for cnt, batch in enumerate(loader_train):\n",
    "        obs_traj, pred_traj_gt, obs_traj_rel, pred_traj_gt_rel, non_linear_ped, \\\n",
    "        loss_mask, V_obs, V_tr = batch\n",
    "\n",
    "        obs_traj = obs_traj[np.newaxis, :]\n",
    "        pred_traj_gt = pred_traj_gt[np.newaxis, :]\n",
    "        obs_traj_rel = obs_traj_rel[np.newaxis, :]\n",
    "        pred_traj_gt_rel = pred_traj_gt_rel[np.newaxis, :]\n",
    "        non_linear_ped = non_linear_ped[np.newaxis, :]\n",
    "        loss_mask = loss_mask[np.newaxis, :]\n",
    "        V_obs = V_obs[np.newaxis, :]\n",
    "        V_tr = V_tr[np.newaxis, :]\n",
    "\n",
    "        identity_spatial = tf.ones((V_obs.shape[1], V_obs.shape[2], V_obs.shape[2])) * \\\n",
    "                           tf.eye(V_obs.shape[2])\n",
    "        identity_temporal = tf.ones((V_obs.shape[2], V_obs.shape[1], V_obs.shape[1])) * \\\n",
    "                            tf.eye(V_obs.shape[1])\n",
    "        identity = [identity_spatial, identity_temporal]\n",
    "\n",
    "        if (cnt + 1) % 128 != 0:\n",
    "            V_obs_list.append(V_obs)\n",
    "            V_tr_list.append(V_tr)\n",
    "            identity_list.append(identity)\n",
    "        else:\n",
    "            is_first_loss = True\n",
    "            batch_count += 1\n",
    "            with tf.GradientTape() as tape:\n",
    "                tape.watch(model.trainable_weights)\n",
    "                V_list = [(model(V_obs, identity),tf.cast(tf.squeeze(V_tr), dtype = tf.float32)) for V_obs, V_tr, identity in zip(V_obs_list,V_tr_list,identity_list)]\n",
    "                loss_ = sum([graph_loss(item[0], item[1]) for item in V_list])/124\n",
    "            grads = tape.gradient(loss_, model.trainable_weights)\n",
    "            \n",
    "            V_obs_list = []\n",
    "            V_tr_list = []\n",
    "            identity_list = []\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "            \n",
    "            train_loss(loss_)\n",
    "            with train_summary_writer.as_default():\n",
    "                tf.summary.scalar('train_loss', train_loss.result(), step=epoch * 25 + batch_count)\n",
    "\n",
    "            print('TRAIN:', '\\t cnt:', cnt, '\\t Loss:', loss_)\n",
    "\n",
    "def valid(epoch, model, loader_val):\n",
    "    global metrics, constant_metrics\n",
    "#     model.eval()\n",
    "    loss_batch = 0\n",
    "    batch_count = 0\n",
    "    is_fst_loss = True\n",
    "    loader_len = len(loader_val)\n",
    "    turn_point = int(loader_len / args.batch_size) * args.batch_size + loader_len % args.batch_size - 1\n",
    "\n",
    "    for cnt, batch in enumerate(loader_val):\n",
    "\n",
    "        obs_traj, pred_traj_gt, obs_traj_rel, pred_traj_gt_rel, non_linear_ped, \\\n",
    "        loss_mask, V_obs, V_tr = batch\n",
    "    \n",
    "        obs_traj = obs_traj[np.newaxis, :]\n",
    "        pred_traj_gt = pred_traj_gt[np.newaxis, :]\n",
    "        obs_traj_rel = obs_traj_rel[np.newaxis, :]\n",
    "        pred_traj_gt_rel = pred_traj_gt_rel[np.newaxis, :]\n",
    "        non_linear_ped = non_linear_ped[np.newaxis, :]\n",
    "        loss_mask = loss_mask[np.newaxis, :]\n",
    "        V_obs = V_obs[np.newaxis, :]\n",
    "        V_tr = V_tr[np.newaxis, :]\n",
    "\n",
    "        identity_spatial = tf.ones((V_obs.shape[1], V_obs.shape[2], V_obs.shape[2])) * tf.eye(V_obs.shape[2])\n",
    "        identity_temporal = tf.ones((V_obs.shape[2], V_obs.shape[1], V_obs.shape[1])) * tf.eye(V_obs.shape[1])\n",
    "        identity = [identity_spatial, identity_temporal]\n",
    "\n",
    "        V_pred = model(V_obs, identity)  # A_obs <8, #, #>\n",
    "\n",
    "        V_tr = tf.cast(tf.squeeze(V_tr), dtype = tf.float32)\n",
    "\n",
    "        if (cnt + 1) % 128 != 0:\n",
    "            l = graph_loss(V_pred, V_tr)\n",
    "\n",
    "            if is_fst_loss:\n",
    "                loss = l\n",
    "                is_fst_loss = False\n",
    "            else:\n",
    "                loss += l\n",
    "\n",
    "        else:\n",
    "            loss = loss / args.batch_size\n",
    "            \n",
    "            batch_count += 1\n",
    "            \n",
    "            valid_loss(loss)\n",
    "            with valid_summary_writer.as_default():\n",
    "                tf.summary.scalar('valid_loss', valid_loss.result(), step=epoch * 6 + batch_count)\n",
    "            is_fst_loss = True\n",
    "            print('VALID:', '\\t cnt:', cnt, '\\t Loss:', loss)\n",
    "\n",
    "def test(model, loader_test, KSTEPS=20):\n",
    "    raw_data_dict = {}\n",
    "    ade_bigls = []\n",
    "    fde_bigls = []\n",
    "\n",
    "    step =0\n",
    "    for batch in tqdm(loader_test):\n",
    "        step += 1\n",
    "        \n",
    "        obs_traj, pred_traj_gt, obs_traj_rel, pred_traj_gt_rel, non_linear_ped, loss_mask, V_obs, V_tr = batch\n",
    "        \n",
    "        obs_traj = obs_traj[np.newaxis, :]\n",
    "        pred_traj_gt = pred_traj_gt[np.newaxis, :]\n",
    "        obs_traj_rel = obs_traj_rel[np.newaxis, :]\n",
    "        pred_traj_gt_rel = pred_traj_gt_rel[np.newaxis, :]\n",
    "        non_linear_ped = non_linear_ped[np.newaxis, :]\n",
    "        loss_mask = loss_mask[np.newaxis, :]\n",
    "        V_obs = V_obs[np.newaxis, :]\n",
    "        V_tr = V_tr[np.newaxis, :]\n",
    "\n",
    "        identity_spatial = tf.ones((V_obs.shape[1], V_obs.shape[2], V_obs.shape[2])) * tf.eye(V_obs.shape[2])\n",
    "        identity_temporal = tf.ones((V_obs.shape[2], V_obs.shape[1], V_obs.shape[1])) * tf.eye(V_obs.shape[1])\n",
    "        identity = [identity_spatial, identity_temporal]\n",
    "        \n",
    "        V_pred = model(V_obs, identity)\n",
    "        V_tr = tf.cast(tf.squeeze(V_tr), dtype = tf.float32)\n",
    "        \n",
    "        num_of_objs = obs_traj_rel.shape[1]\n",
    "        V_pred, V_tr = V_pred[:, :num_of_objs, :], V_tr[:, :num_of_objs, :]\n",
    "        \n",
    "        sx = tf.math.exp(V_pred[:,:,2]) #sx\n",
    "        sy = tf.math.exp(V_pred[:,:,3]) #sy\n",
    "        corr = tf.math.tanh(V_pred[:,:,4]) #corr\n",
    "        \n",
    "        cov = np.zeros((V_pred.shape[0],V_pred.shape[1],2,2))\n",
    "        cov[:,:,0,0]= sx*sx\n",
    "        cov[:,:,0,1]= corr*sx*sy\n",
    "        cov[:,:,1,0]= corr*sx*sy\n",
    "        cov[:,:,1,1]= sy*sy\n",
    "        cov = tf.convert_to_tensor(cov, dtype=tf.float32)\n",
    "        mean = V_pred[:,:,0:2]\n",
    "        \n",
    "        mvnormal = tfp.distributions.MultivariateNormalFullCovariance(mean, cov)\n",
    "        \n",
    "        ade_ls = {}\n",
    "        fde_ls = {}\n",
    "        V_x = seq_to_nodes(tf.identity(obs_traj))\n",
    "        V_x_rel_to_abs = nodes_rel_to_nodes_abs(tf.identity(tf.squeeze(V_obs[:,:,:,:2])), tf.identity(V_x[0,:,:]))\n",
    "        V_y_rel_to_abs = nodes_rel_to_nodes_abs(tf.identity(tf.squeeze(V_tr)),tf.identity(V_x[-1,:,:]))\n",
    "        \n",
    "        raw_data_dict[step] = {}\n",
    "        raw_data_dict[step]['obs'] = copy.deepcopy(V_x_rel_to_abs)\n",
    "        raw_data_dict[step]['trgt'] = copy.deepcopy(V_y_rel_to_abs)\n",
    "        raw_data_dict[step]['pred'] = []\n",
    "        \n",
    "        for n in range(num_of_objs):\n",
    "            ade_ls[n]=[]\n",
    "            fde_ls[n]=[]\n",
    "        \n",
    "        for k in range(KSTEPS):\n",
    "\n",
    "            V_pred = mvnormal.sample()\n",
    "    \n",
    "            V_pred_rel_to_abs = nodes_rel_to_nodes_abs(tf.identity(tf.squeeze(V_pred)), tf.identity(V_x[-1,:,:]))\n",
    "\n",
    "            raw_data_dict[step]['pred'].append(copy.deepcopy(V_pred_rel_to_abs))\n",
    "\n",
    "            for n in range(num_of_objs):\n",
    "                pred = []\n",
    "                target = []\n",
    "                obsrvs = []\n",
    "                number_of = []\n",
    "                pred.append(V_pred_rel_to_abs[:,n:n+1,:])\n",
    "                \n",
    "                target.append(V_y_rel_to_abs[:,n:n+1,:])\n",
    "                obsrvs.append(V_x_rel_to_abs[:,n:n+1,:])\n",
    "                number_of.append(1)\n",
    "                \n",
    "                ade_ls[n].append(ade(pred,target,number_of))\n",
    "                fde_ls[n].append(fde(pred,target,number_of))\n",
    "                \n",
    "\n",
    "                   \n",
    "        for n in range(num_of_objs):\n",
    "            ade_bigls.append(min(ade_ls[n]))\n",
    "            fde_bigls.append(min(fde_ls[n]))\n",
    "\n",
    "        ADE_loss(sum(ade_bigls)/len(ade_bigls))\n",
    "        FDE_loss(sum(fde_bigls)/len(fde_bigls))\n",
    "        with test_summary_writer.as_default():\n",
    "            tf.summary.scalar('ADE_loss', ADE_loss.result(), step=step)\n",
    "            tf.summary.scalar('FDE_loss', FDE_loss.result(), step=step)\n",
    "        ADE_loss.reset_states()\n",
    "        FDE_loss.reset_states()\n",
    "    ade_ = sum(ade_bigls)/len(ade_bigls)\n",
    "    fde_ = sum(fde_bigls)/len(fde_bigls)\n",
    "    return ade_,fde_,raw_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c05koZy3vU0D",
    "outputId": "fffab470-33c3-477a-bc75-819250f24d88",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "TRAIN: \t cnt: 127 \t Loss: tf.Tensor(1.8883142, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 255 \t Loss: tf.Tensor(1.8822917, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 383 \t Loss: tf.Tensor(1.8799993, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 511 \t Loss: tf.Tensor(1.8763658, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 639 \t Loss: tf.Tensor(1.8756995, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 767 \t Loss: tf.Tensor(1.8794144, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 895 \t Loss: tf.Tensor(1.8713725, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1023 \t Loss: tf.Tensor(1.86997, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1151 \t Loss: tf.Tensor(1.8652644, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1279 \t Loss: tf.Tensor(1.863199, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1407 \t Loss: tf.Tensor(1.8606985, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1535 \t Loss: tf.Tensor(1.8585362, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1663 \t Loss: tf.Tensor(1.8584445, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1791 \t Loss: tf.Tensor(1.8577721, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1919 \t Loss: tf.Tensor(1.8516386, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2047 \t Loss: tf.Tensor(1.8473428, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2175 \t Loss: tf.Tensor(1.8440627, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2303 \t Loss: tf.Tensor(1.8411341, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2431 \t Loss: tf.Tensor(1.8304831, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2559 \t Loss: tf.Tensor(1.8286004, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2687 \t Loss: tf.Tensor(1.8146329, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2815 \t Loss: tf.Tensor(1.810451, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2943 \t Loss: tf.Tensor(1.7962505, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3071 \t Loss: tf.Tensor(1.7911589, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3199 \t Loss: tf.Tensor(1.7706107, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 127 \t Loss: tf.Tensor(1.7335966, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 255 \t Loss: tf.Tensor(1.7274503, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 383 \t Loss: tf.Tensor(1.7208873, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 511 \t Loss: tf.Tensor(1.7235324, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 639 \t Loss: tf.Tensor(1.7214466, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 767 \t Loss: tf.Tensor(1.708509, shape=(), dtype=float32)\n",
      "Epoch:  1\n",
      "TRAIN: \t cnt: 127 \t Loss: tf.Tensor(1.772228, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 255 \t Loss: tf.Tensor(1.7650033, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 383 \t Loss: tf.Tensor(1.7516174, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 511 \t Loss: tf.Tensor(1.7395923, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 639 \t Loss: tf.Tensor(1.6877749, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 767 \t Loss: tf.Tensor(1.5867982, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 895 \t Loss: tf.Tensor(1.6097327, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1023 \t Loss: tf.Tensor(1.4608558, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1151 \t Loss: tf.Tensor(1.3697293, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1279 \t Loss: tf.Tensor(1.3096663, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1407 \t Loss: tf.Tensor(1.2148439, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1535 \t Loss: tf.Tensor(1.1132851, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1663 \t Loss: tf.Tensor(0.94398725, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1791 \t Loss: tf.Tensor(0.7852982, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1919 \t Loss: tf.Tensor(0.59646416, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2047 \t Loss: tf.Tensor(0.2178916, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2175 \t Loss: tf.Tensor(0.6404114, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2303 \t Loss: tf.Tensor(0.694477, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2431 \t Loss: tf.Tensor(6.4306693, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2559 \t Loss: tf.Tensor(0.13505355, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2687 \t Loss: tf.Tensor(-0.2934458, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2815 \t Loss: tf.Tensor(0.05027484, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2943 \t Loss: tf.Tensor(0.007607085, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3071 \t Loss: tf.Tensor(0.1476842, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3199 \t Loss: tf.Tensor(0.21888132, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 127 \t Loss: tf.Tensor(0.41974106, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 255 \t Loss: tf.Tensor(0.36539373, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 383 \t Loss: tf.Tensor(0.30507115, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 511 \t Loss: tf.Tensor(0.34659144, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 639 \t Loss: tf.Tensor(0.31433067, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 767 \t Loss: tf.Tensor(0.20544451, shape=(), dtype=float32)\n",
      "Epoch:  2\n",
      "TRAIN: \t cnt: 127 \t Loss: tf.Tensor(0.25806695, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 255 \t Loss: tf.Tensor(0.35119268, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 383 \t Loss: tf.Tensor(0.4173463, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 511 \t Loss: tf.Tensor(0.4680591, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 639 \t Loss: tf.Tensor(0.3904025, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 767 \t Loss: tf.Tensor(0.19627044, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 895 \t Loss: tf.Tensor(0.3260978, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1023 \t Loss: tf.Tensor(0.278724, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1151 \t Loss: tf.Tensor(0.023484714, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1279 \t Loss: tf.Tensor(-0.011631334, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1407 \t Loss: tf.Tensor(0.018216453, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1535 \t Loss: tf.Tensor(0.021215755, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1663 \t Loss: tf.Tensor(-0.06159352, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1791 \t Loss: tf.Tensor(-0.047894064, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1919 \t Loss: tf.Tensor(-0.10143935, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2047 \t Loss: tf.Tensor(-0.3137301, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2175 \t Loss: tf.Tensor(-0.48958066, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2303 \t Loss: tf.Tensor(-0.62396884, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2431 \t Loss: tf.Tensor(0.32390344, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2559 \t Loss: tf.Tensor(0.08719118, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2687 \t Loss: tf.Tensor(-0.7670019, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2815 \t Loss: tf.Tensor(-0.8006143, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2943 \t Loss: tf.Tensor(-0.8705102, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3071 \t Loss: tf.Tensor(-0.7402087, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3199 \t Loss: tf.Tensor(-0.5794681, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 127 \t Loss: tf.Tensor(-0.4890995, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 255 \t Loss: tf.Tensor(-0.5504024, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 383 \t Loss: tf.Tensor(-0.61438376, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 511 \t Loss: tf.Tensor(-0.5913138, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 639 \t Loss: tf.Tensor(-0.6303268, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 767 \t Loss: tf.Tensor(-0.7088502, shape=(), dtype=float32)\n",
      "Epoch:  3\n",
      "TRAIN: \t cnt: 127 \t Loss: tf.Tensor(-0.71483034, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 255 \t Loss: tf.Tensor(-0.7007415, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 383 \t Loss: tf.Tensor(-0.6644618, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 511 \t Loss: tf.Tensor(-0.63902247, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 639 \t Loss: tf.Tensor(-0.7490496, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 767 \t Loss: tf.Tensor(-0.9081957, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 895 \t Loss: tf.Tensor(-0.9515522, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1023 \t Loss: tf.Tensor(-1.0071326, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1151 \t Loss: tf.Tensor(-1.248498, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1279 \t Loss: tf.Tensor(-1.2884936, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1407 \t Loss: tf.Tensor(-1.4190568, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1535 \t Loss: tf.Tensor(-1.5942003, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1663 \t Loss: tf.Tensor(-1.0937752, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1791 \t Loss: tf.Tensor(-1.0967722, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1919 \t Loss: tf.Tensor(-1.7249902, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2047 \t Loss: tf.Tensor(-1.8412274, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2175 \t Loss: tf.Tensor(-1.3563156, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2303 \t Loss: tf.Tensor(-1.8756746, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2431 \t Loss: tf.Tensor(-0.71690446, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: \t cnt: 2559 \t Loss: tf.Tensor(-1.833419, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2687 \t Loss: tf.Tensor(-2.0158515, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2815 \t Loss: tf.Tensor(-1.8645903, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2943 \t Loss: tf.Tensor(-1.9747514, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3071 \t Loss: tf.Tensor(-1.8362759, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3199 \t Loss: tf.Tensor(-1.8482313, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 127 \t Loss: tf.Tensor(-1.6852822, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 255 \t Loss: tf.Tensor(-1.6392711, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 383 \t Loss: tf.Tensor(-1.5989972, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 511 \t Loss: tf.Tensor(-1.6133004, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 639 \t Loss: tf.Tensor(-1.4430165, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 767 \t Loss: tf.Tensor(-1.1516627, shape=(), dtype=float32)\n",
      "Epoch:  4\n",
      "TRAIN: \t cnt: 127 \t Loss: tf.Tensor(-1.1793005, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 255 \t Loss: tf.Tensor(-1.6298155, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 383 \t Loss: tf.Tensor(-1.7372229, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 511 \t Loss: tf.Tensor(-1.7577903, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 639 \t Loss: tf.Tensor(-1.7546417, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 767 \t Loss: tf.Tensor(-1.8466057, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 895 \t Loss: tf.Tensor(-2.0284731, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1023 \t Loss: tf.Tensor(-2.0255108, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1151 \t Loss: tf.Tensor(-1.4198668, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1279 \t Loss: tf.Tensor(-2.344195, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1407 \t Loss: tf.Tensor(-2.2500641, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1535 \t Loss: tf.Tensor(-2.3159733, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1663 \t Loss: tf.Tensor(-1.9515736, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1791 \t Loss: tf.Tensor(-2.002646, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1919 \t Loss: tf.Tensor(-2.7539384, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2047 \t Loss: tf.Tensor(-2.5191774, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2175 \t Loss: tf.Tensor(-2.1532152, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2303 \t Loss: tf.Tensor(-2.997523, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2431 \t Loss: tf.Tensor(-1.2032702, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2559 \t Loss: tf.Tensor(-1.9173994, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2687 \t Loss: tf.Tensor(-2.6987402, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2815 \t Loss: tf.Tensor(-2.2984526, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2943 \t Loss: tf.Tensor(-2.217627, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3071 \t Loss: tf.Tensor(-1.8903668, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3199 \t Loss: tf.Tensor(-2.217484, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 127 \t Loss: tf.Tensor(-2.1181636, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 255 \t Loss: tf.Tensor(-2.0752902, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 383 \t Loss: tf.Tensor(-2.1847212, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 511 \t Loss: tf.Tensor(-2.1129572, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 639 \t Loss: tf.Tensor(-2.0369449, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 767 \t Loss: tf.Tensor(-1.9366162, shape=(), dtype=float32)\n",
      "Epoch:  5\n",
      "TRAIN: \t cnt: 127 \t Loss: tf.Tensor(-2.0580769, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 255 \t Loss: tf.Tensor(-2.1022153, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 383 \t Loss: tf.Tensor(-2.126047, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 511 \t Loss: tf.Tensor(-2.202795, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 639 \t Loss: tf.Tensor(-2.1331544, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 767 \t Loss: tf.Tensor(-2.0950131, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 895 \t Loss: tf.Tensor(-2.3488047, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1023 \t Loss: tf.Tensor(-1.9299772, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1151 \t Loss: tf.Tensor(-2.6133857, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1279 \t Loss: tf.Tensor(-2.925753, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1407 \t Loss: tf.Tensor(-2.8137746, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1535 \t Loss: tf.Tensor(-3.0499086, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1663 \t Loss: tf.Tensor(-2.2490256, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1791 \t Loss: tf.Tensor(-1.7208521, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1919 \t Loss: tf.Tensor(-3.5303152, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2047 \t Loss: tf.Tensor(-3.6102955, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2175 \t Loss: tf.Tensor(-3.0036786, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2303 \t Loss: tf.Tensor(-3.6123002, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2431 \t Loss: tf.Tensor(-2.682349, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2559 \t Loss: tf.Tensor(-3.3522599, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2687 \t Loss: tf.Tensor(-3.2612813, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2815 \t Loss: tf.Tensor(-3.7407496, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2943 \t Loss: tf.Tensor(-2.6447313, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3071 \t Loss: tf.Tensor(-3.345859, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3199 \t Loss: tf.Tensor(-3.109509, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 127 \t Loss: tf.Tensor(-2.177245, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 255 \t Loss: tf.Tensor(-2.0556512, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 383 \t Loss: tf.Tensor(-2.3073773, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 511 \t Loss: tf.Tensor(-2.2587206, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 639 \t Loss: tf.Tensor(-2.0726862, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 767 \t Loss: tf.Tensor(-1.6758916, shape=(), dtype=float32)\n",
      "Epoch:  6\n",
      "TRAIN: \t cnt: 127 \t Loss: tf.Tensor(-1.957538, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 255 \t Loss: tf.Tensor(-2.4755418, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 383 \t Loss: tf.Tensor(-2.8357444, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 511 \t Loss: tf.Tensor(-2.992284, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 639 \t Loss: tf.Tensor(-2.7935424, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 767 \t Loss: tf.Tensor(-2.4801815, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 895 \t Loss: tf.Tensor(-2.6659315, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1023 \t Loss: tf.Tensor(-2.584514, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1151 \t Loss: tf.Tensor(-2.53195, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1279 \t Loss: tf.Tensor(-2.655737, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1407 \t Loss: tf.Tensor(-2.8055124, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1535 \t Loss: tf.Tensor(-3.1898115, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1663 \t Loss: tf.Tensor(-2.8683083, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1791 \t Loss: tf.Tensor(-2.7553082, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1919 \t Loss: tf.Tensor(-3.6018217, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2047 \t Loss: tf.Tensor(-3.660345, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2175 \t Loss: tf.Tensor(-3.6544902, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2303 \t Loss: tf.Tensor(-4.273425, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2431 \t Loss: tf.Tensor(-3.0245056, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2559 \t Loss: tf.Tensor(-3.6754148, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2687 \t Loss: tf.Tensor(-1.6760757, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2815 \t Loss: tf.Tensor(-4.005445, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2943 \t Loss: tf.Tensor(-3.6967754, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3071 \t Loss: tf.Tensor(-2.7426736, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3199 \t Loss: tf.Tensor(-3.1866665, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 127 \t Loss: tf.Tensor(-2.9846683, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 255 \t Loss: tf.Tensor(-2.9085526, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 383 \t Loss: tf.Tensor(-3.0484338, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 511 \t Loss: tf.Tensor(-2.9528103, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 639 \t Loss: tf.Tensor(-2.8215463, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 767 \t Loss: tf.Tensor(-2.6230357, shape=(), dtype=float32)\n",
      "Epoch:  7\n",
      "TRAIN: \t cnt: 127 \t Loss: tf.Tensor(-2.7531023, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 255 \t Loss: tf.Tensor(-2.8788726, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 383 \t Loss: tf.Tensor(-2.8847916, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 511 \t Loss: tf.Tensor(-2.9168084, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 639 \t Loss: tf.Tensor(-2.766677, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 767 \t Loss: tf.Tensor(-2.5017238, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 895 \t Loss: tf.Tensor(-2.7466986, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: \t cnt: 1023 \t Loss: tf.Tensor(-2.648402, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1151 \t Loss: tf.Tensor(-2.921479, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1279 \t Loss: tf.Tensor(-3.0468466, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1407 \t Loss: tf.Tensor(-3.20812, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1535 \t Loss: tf.Tensor(-3.4970891, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1663 \t Loss: tf.Tensor(-2.9355884, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1791 \t Loss: tf.Tensor(-3.0716422, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1919 \t Loss: tf.Tensor(-4.13975, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2047 \t Loss: tf.Tensor(-4.1034493, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2175 \t Loss: tf.Tensor(-3.7367582, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2303 \t Loss: tf.Tensor(-4.7711215, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2431 \t Loss: tf.Tensor(-3.072369, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2559 \t Loss: tf.Tensor(-4.282543, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2687 \t Loss: tf.Tensor(-3.803426, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2815 \t Loss: tf.Tensor(-4.385376, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2943 \t Loss: tf.Tensor(-4.2471433, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3071 \t Loss: tf.Tensor(-4.11354, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3199 \t Loss: tf.Tensor(-4.2797065, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 127 \t Loss: tf.Tensor(-3.3917603, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 255 \t Loss: tf.Tensor(-3.115741, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 383 \t Loss: tf.Tensor(-3.6227286, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 511 \t Loss: tf.Tensor(-3.4063416, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 639 \t Loss: tf.Tensor(-2.8547392, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 767 \t Loss: tf.Tensor(-2.1795924, shape=(), dtype=float32)\n",
      "Epoch:  8\n",
      "TRAIN: \t cnt: 127 \t Loss: tf.Tensor(-2.6301749, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 255 \t Loss: tf.Tensor(-2.9413104, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 383 \t Loss: tf.Tensor(-3.510154, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 511 \t Loss: tf.Tensor(-3.8227382, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 639 \t Loss: tf.Tensor(-3.5939808, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 767 \t Loss: tf.Tensor(-3.2134302, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 895 \t Loss: tf.Tensor(-3.4591794, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1023 \t Loss: tf.Tensor(-3.2738543, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1151 \t Loss: tf.Tensor(-3.3796701, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1279 \t Loss: tf.Tensor(-3.4913607, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1407 \t Loss: tf.Tensor(-3.6050847, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1535 \t Loss: tf.Tensor(-3.877121, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1663 \t Loss: tf.Tensor(-3.3459094, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1791 \t Loss: tf.Tensor(-3.4184287, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1919 \t Loss: tf.Tensor(-4.605627, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2047 \t Loss: tf.Tensor(-4.739118, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2175 \t Loss: tf.Tensor(-4.3990355, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2303 \t Loss: tf.Tensor(-5.1559196, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2431 \t Loss: tf.Tensor(-2.9890573, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2559 \t Loss: tf.Tensor(-4.581632, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2687 \t Loss: tf.Tensor(-4.3303227, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2815 \t Loss: tf.Tensor(-4.1843204, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2943 \t Loss: tf.Tensor(-4.688394, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3071 \t Loss: tf.Tensor(-4.459805, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3199 \t Loss: tf.Tensor(-4.167402, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 127 \t Loss: tf.Tensor(-3.5819507, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 255 \t Loss: tf.Tensor(-3.4094675, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 383 \t Loss: tf.Tensor(-3.795843, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 511 \t Loss: tf.Tensor(-3.598678, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 639 \t Loss: tf.Tensor(-3.1645684, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 767 \t Loss: tf.Tensor(-2.7219293, shape=(), dtype=float32)\n",
      "Epoch:  9\n",
      "TRAIN: \t cnt: 127 \t Loss: tf.Tensor(-3.1083112, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 255 \t Loss: tf.Tensor(-3.348728, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 383 \t Loss: tf.Tensor(-3.7490704, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 511 \t Loss: tf.Tensor(-4.038148, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 639 \t Loss: tf.Tensor(-3.8106751, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 767 \t Loss: tf.Tensor(-3.401781, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 895 \t Loss: tf.Tensor(-3.7884588, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1023 \t Loss: tf.Tensor(-3.5490782, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1151 \t Loss: tf.Tensor(-3.6619003, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1279 \t Loss: tf.Tensor(-3.8048472, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1407 \t Loss: tf.Tensor(-3.8759181, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1535 \t Loss: tf.Tensor(-4.3382363, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1663 \t Loss: tf.Tensor(-3.741317, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1791 \t Loss: tf.Tensor(-3.7035007, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1919 \t Loss: tf.Tensor(-5.024063, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2047 \t Loss: tf.Tensor(-5.1454635, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2175 \t Loss: tf.Tensor(-4.749466, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2303 \t Loss: tf.Tensor(-5.4124026, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2431 \t Loss: tf.Tensor(-3.1605628, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2559 \t Loss: tf.Tensor(-3.5773873, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2687 \t Loss: tf.Tensor(-3.5398657, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2815 \t Loss: tf.Tensor(-3.7348895, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2943 \t Loss: tf.Tensor(-4.4588456, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3071 \t Loss: tf.Tensor(-4.2467203, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3199 \t Loss: tf.Tensor(-3.8814778, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 127 \t Loss: tf.Tensor(-3.4153328, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 255 \t Loss: tf.Tensor(-3.3566785, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 383 \t Loss: tf.Tensor(-3.5011287, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 511 \t Loss: tf.Tensor(-3.383824, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 639 \t Loss: tf.Tensor(-3.2057738, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 767 \t Loss: tf.Tensor(-3.0063827, shape=(), dtype=float32)\n",
      "Epoch:  10\n",
      "TRAIN: \t cnt: 127 \t Loss: tf.Tensor(-3.2134647, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 255 \t Loss: tf.Tensor(-3.3345602, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 383 \t Loss: tf.Tensor(-3.6238463, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 511 \t Loss: tf.Tensor(-4.0241804, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 639 \t Loss: tf.Tensor(-3.9811032, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 767 \t Loss: tf.Tensor(-3.5726295, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 895 \t Loss: tf.Tensor(-4.1084466, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1023 \t Loss: tf.Tensor(-3.8035178, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1151 \t Loss: tf.Tensor(-3.9839199, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1279 \t Loss: tf.Tensor(-4.0755005, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1407 \t Loss: tf.Tensor(-4.1204534, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1535 \t Loss: tf.Tensor(-4.386044, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1663 \t Loss: tf.Tensor(-3.6406608, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1791 \t Loss: tf.Tensor(-3.6538248, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1919 \t Loss: tf.Tensor(-4.6316485, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2047 \t Loss: tf.Tensor(-4.6948156, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2175 \t Loss: tf.Tensor(-4.5033336, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2303 \t Loss: tf.Tensor(-4.8545146, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2431 \t Loss: tf.Tensor(-4.0286417, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2559 \t Loss: tf.Tensor(-4.7668886, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2687 \t Loss: tf.Tensor(-4.6403694, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2815 \t Loss: tf.Tensor(-4.850467, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2943 \t Loss: tf.Tensor(-4.814462, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3071 \t Loss: tf.Tensor(-4.7149806, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3199 \t Loss: tf.Tensor(-4.6081223, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 127 \t Loss: tf.Tensor(-3.9238865, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID: \t cnt: 255 \t Loss: tf.Tensor(-3.5495763, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 383 \t Loss: tf.Tensor(-4.1809115, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 511 \t Loss: tf.Tensor(-3.7993672, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 639 \t Loss: tf.Tensor(-2.9767208, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 767 \t Loss: tf.Tensor(-1.9858203, shape=(), dtype=float32)\n",
      "Epoch:  11\n",
      "TRAIN: \t cnt: 127 \t Loss: tf.Tensor(-2.6219137, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 255 \t Loss: tf.Tensor(-2.6425402, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 383 \t Loss: tf.Tensor(-3.7848177, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 511 \t Loss: tf.Tensor(-5.212933, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 639 \t Loss: tf.Tensor(-4.8981013, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 767 \t Loss: tf.Tensor(-3.7803192, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 895 \t Loss: tf.Tensor(-5.060372, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1023 \t Loss: tf.Tensor(-4.0590186, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1151 \t Loss: tf.Tensor(-4.464185, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1279 \t Loss: tf.Tensor(-4.538576, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1407 \t Loss: tf.Tensor(-4.358034, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1535 \t Loss: tf.Tensor(-4.9493227, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1663 \t Loss: tf.Tensor(-3.5313845, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1791 \t Loss: tf.Tensor(-3.7287772, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1919 \t Loss: tf.Tensor(-5.148916, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2047 \t Loss: tf.Tensor(-5.1317797, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2175 \t Loss: tf.Tensor(-4.7108226, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2303 \t Loss: tf.Tensor(-5.1544085, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2431 \t Loss: tf.Tensor(-4.099817, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2559 \t Loss: tf.Tensor(-4.950781, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2687 \t Loss: tf.Tensor(-4.9108043, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2815 \t Loss: tf.Tensor(-5.0541277, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2943 \t Loss: tf.Tensor(-4.964663, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3071 \t Loss: tf.Tensor(-4.8477955, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3199 \t Loss: tf.Tensor(-4.6902347, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 127 \t Loss: tf.Tensor(-3.9931753, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 255 \t Loss: tf.Tensor(-3.6234612, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 383 \t Loss: tf.Tensor(-4.2041473, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 511 \t Loss: tf.Tensor(-3.8545027, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 639 \t Loss: tf.Tensor(-3.0710552, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 767 \t Loss: tf.Tensor(-2.112254, shape=(), dtype=float32)\n",
      "Epoch:  12\n",
      "TRAIN: \t cnt: 127 \t Loss: tf.Tensor(-2.7250652, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 255 \t Loss: tf.Tensor(-2.7406096, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 383 \t Loss: tf.Tensor(-3.859339, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 511 \t Loss: tf.Tensor(-5.2745485, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 639 \t Loss: tf.Tensor(-4.937909, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 767 \t Loss: tf.Tensor(-3.8410826, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 895 \t Loss: tf.Tensor(-5.09179, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1023 \t Loss: tf.Tensor(-4.0921993, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1151 \t Loss: tf.Tensor(-4.5175524, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1279 \t Loss: tf.Tensor(-4.5671535, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1407 \t Loss: tf.Tensor(-4.4420047, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1535 \t Loss: tf.Tensor(-4.994368, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1663 \t Loss: tf.Tensor(-3.6590364, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1791 \t Loss: tf.Tensor(-3.8324409, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1919 \t Loss: tf.Tensor(-5.18622, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2047 \t Loss: tf.Tensor(-5.1449857, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2175 \t Loss: tf.Tensor(-4.7372036, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2303 \t Loss: tf.Tensor(-5.161436, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2431 \t Loss: tf.Tensor(-4.1298556, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2559 \t Loss: tf.Tensor(-4.9486713, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2687 \t Loss: tf.Tensor(-4.9565043, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2815 \t Loss: tf.Tensor(-5.072391, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2943 \t Loss: tf.Tensor(-5.0088496, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3071 \t Loss: tf.Tensor(-4.8720856, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3199 \t Loss: tf.Tensor(-4.745856, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 127 \t Loss: tf.Tensor(-4.0028243, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 255 \t Loss: tf.Tensor(-3.6476657, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 383 \t Loss: tf.Tensor(-4.222543, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 511 \t Loss: tf.Tensor(-3.8539329, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 639 \t Loss: tf.Tensor(-3.0661325, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 767 \t Loss: tf.Tensor(-2.139021, shape=(), dtype=float32)\n",
      "Epoch:  13\n",
      "TRAIN: \t cnt: 127 \t Loss: tf.Tensor(-2.7213218, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 255 \t Loss: tf.Tensor(-2.721637, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 383 \t Loss: tf.Tensor(-3.8637953, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 511 \t Loss: tf.Tensor(-5.2911267, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 639 \t Loss: tf.Tensor(-4.9723825, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 767 \t Loss: tf.Tensor(-3.9038808, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 895 \t Loss: tf.Tensor(-5.1198277, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1023 \t Loss: tf.Tensor(-4.1430917, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1151 \t Loss: tf.Tensor(-4.554608, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1279 \t Loss: tf.Tensor(-4.5835, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1407 \t Loss: tf.Tensor(-4.467678, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1535 \t Loss: tf.Tensor(-5.0336504, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1663 \t Loss: tf.Tensor(-3.6675823, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1791 \t Loss: tf.Tensor(-3.8710866, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1919 \t Loss: tf.Tensor(-5.2552304, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2047 \t Loss: tf.Tensor(-5.194672, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2175 \t Loss: tf.Tensor(-4.770535, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2303 \t Loss: tf.Tensor(-5.210381, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2431 \t Loss: tf.Tensor(-4.1504755, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2559 \t Loss: tf.Tensor(-4.983348, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2687 \t Loss: tf.Tensor(-4.98721, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2815 \t Loss: tf.Tensor(-5.103548, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2943 \t Loss: tf.Tensor(-5.0457187, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3071 \t Loss: tf.Tensor(-4.8990884, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3199 \t Loss: tf.Tensor(-4.7704573, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 127 \t Loss: tf.Tensor(-4.000826, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 255 \t Loss: tf.Tensor(-3.6381338, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 383 \t Loss: tf.Tensor(-4.2227173, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 511 \t Loss: tf.Tensor(-3.8402126, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 639 \t Loss: tf.Tensor(-3.0220084, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 767 \t Loss: tf.Tensor(-2.069699, shape=(), dtype=float32)\n",
      "Epoch:  14\n",
      "TRAIN: \t cnt: 127 \t Loss: tf.Tensor(-2.6620657, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 255 \t Loss: tf.Tensor(-2.6633506, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 383 \t Loss: tf.Tensor(-3.850197, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 511 \t Loss: tf.Tensor(-5.312738, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 639 \t Loss: tf.Tensor(-5.0013785, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 767 \t Loss: tf.Tensor(-3.9360225, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 895 \t Loss: tf.Tensor(-5.1493096, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1023 \t Loss: tf.Tensor(-4.200762, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1151 \t Loss: tf.Tensor(-4.5828032, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1279 \t Loss: tf.Tensor(-4.5943313, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1407 \t Loss: tf.Tensor(-4.4863577, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1535 \t Loss: tf.Tensor(-5.051776, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1663 \t Loss: tf.Tensor(-3.65621, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1791 \t Loss: tf.Tensor(-3.8875902, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: \t cnt: 1919 \t Loss: tf.Tensor(-5.2776327, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2047 \t Loss: tf.Tensor(-5.213925, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2175 \t Loss: tf.Tensor(-4.7902083, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2303 \t Loss: tf.Tensor(-5.2296796, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2431 \t Loss: tf.Tensor(-4.1662803, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2559 \t Loss: tf.Tensor(-5.00257, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2687 \t Loss: tf.Tensor(-5.0126214, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2815 \t Loss: tf.Tensor(-5.118327, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2943 \t Loss: tf.Tensor(-5.0703635, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3071 \t Loss: tf.Tensor(-4.915835, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3199 \t Loss: tf.Tensor(-4.790986, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 127 \t Loss: tf.Tensor(-4.017537, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 255 \t Loss: tf.Tensor(-3.6570008, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 383 \t Loss: tf.Tensor(-4.2379756, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 511 \t Loss: tf.Tensor(-3.848856, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 639 \t Loss: tf.Tensor(-3.0266654, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 767 \t Loss: tf.Tensor(-2.0771818, shape=(), dtype=float32)\n",
      "Epoch:  15\n",
      "TRAIN: \t cnt: 127 \t Loss: tf.Tensor(-2.6683524, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 255 \t Loss: tf.Tensor(-2.6717196, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 383 \t Loss: tf.Tensor(-3.8651175, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 511 \t Loss: tf.Tensor(-5.333414, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 639 \t Loss: tf.Tensor(-5.0215774, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 767 \t Loss: tf.Tensor(-3.9551284, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 895 \t Loss: tf.Tensor(-5.164916, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1023 \t Loss: tf.Tensor(-4.239032, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1151 \t Loss: tf.Tensor(-4.602023, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1279 \t Loss: tf.Tensor(-4.600799, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1407 \t Loss: tf.Tensor(-4.508362, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1535 \t Loss: tf.Tensor(-5.07216, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1663 \t Loss: tf.Tensor(-3.6547613, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1791 \t Loss: tf.Tensor(-3.9037774, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1919 \t Loss: tf.Tensor(-5.3054194, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2047 \t Loss: tf.Tensor(-5.2360888, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2175 \t Loss: tf.Tensor(-4.8086805, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2303 \t Loss: tf.Tensor(-5.24941, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2431 \t Loss: tf.Tensor(-4.179245, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2559 \t Loss: tf.Tensor(-5.0194383, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2687 \t Loss: tf.Tensor(-5.038305, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2815 \t Loss: tf.Tensor(-5.135917, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2943 \t Loss: tf.Tensor(-5.099488, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3071 \t Loss: tf.Tensor(-4.934683, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3199 \t Loss: tf.Tensor(-4.8148737, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 127 \t Loss: tf.Tensor(-4.026855, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 255 \t Loss: tf.Tensor(-3.6644964, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 383 \t Loss: tf.Tensor(-4.248288, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 511 \t Loss: tf.Tensor(-3.85071, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 639 \t Loss: tf.Tensor(-3.0177104, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 767 \t Loss: tf.Tensor(-2.0678706, shape=(), dtype=float32)\n",
      "Epoch:  16\n",
      "TRAIN: \t cnt: 127 \t Loss: tf.Tensor(-2.6586442, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 255 \t Loss: tf.Tensor(-2.6636868, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 383 \t Loss: tf.Tensor(-3.8700926, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 511 \t Loss: tf.Tensor(-5.350883, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 639 \t Loss: tf.Tensor(-5.04103, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 767 \t Loss: tf.Tensor(-3.9720926, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 895 \t Loss: tf.Tensor(-5.181878, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1023 \t Loss: tf.Tensor(-4.2756557, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1151 \t Loss: tf.Tensor(-4.6168694, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1279 \t Loss: tf.Tensor(-4.6054482, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1407 \t Loss: tf.Tensor(-4.526571, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1535 \t Loss: tf.Tensor(-5.090679, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1663 \t Loss: tf.Tensor(-3.6538043, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1791 \t Loss: tf.Tensor(-3.9184802, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1919 \t Loss: tf.Tensor(-5.3315783, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2047 \t Loss: tf.Tensor(-5.2565713, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2175 \t Loss: tf.Tensor(-4.825663, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2303 \t Loss: tf.Tensor(-5.2678676, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2431 \t Loss: tf.Tensor(-4.1923056, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2559 \t Loss: tf.Tensor(-5.037183, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2687 \t Loss: tf.Tensor(-5.061845, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2815 \t Loss: tf.Tensor(-5.152144, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2943 \t Loss: tf.Tensor(-5.125095, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3071 \t Loss: tf.Tensor(-4.9528594, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3199 \t Loss: tf.Tensor(-4.836732, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 127 \t Loss: tf.Tensor(-4.0375056, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 255 \t Loss: tf.Tensor(-3.6731553, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 383 \t Loss: tf.Tensor(-4.259109, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 511 \t Loss: tf.Tensor(-3.854508, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 639 \t Loss: tf.Tensor(-3.0132153, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 767 \t Loss: tf.Tensor(-2.065305, shape=(), dtype=float32)\n",
      "Epoch:  17\n",
      "TRAIN: \t cnt: 127 \t Loss: tf.Tensor(-2.654443, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 255 \t Loss: tf.Tensor(-2.662348, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 383 \t Loss: tf.Tensor(-3.8776577, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 511 \t Loss: tf.Tensor(-5.369934, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 639 \t Loss: tf.Tensor(-5.0599694, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 767 \t Loss: tf.Tensor(-3.98591, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 895 \t Loss: tf.Tensor(-5.1969132, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1023 \t Loss: tf.Tensor(-4.310033, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1151 \t Loss: tf.Tensor(-4.627914, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1279 \t Loss: tf.Tensor(-4.6079874, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1407 \t Loss: tf.Tensor(-4.543375, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1535 \t Loss: tf.Tensor(-5.107381, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1663 \t Loss: tf.Tensor(-3.6507916, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1791 \t Loss: tf.Tensor(-3.9298356, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1919 \t Loss: tf.Tensor(-5.3548884, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2047 \t Loss: tf.Tensor(-5.275619, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2175 \t Loss: tf.Tensor(-4.8417883, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2303 \t Loss: tf.Tensor(-5.2849174, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2431 \t Loss: tf.Tensor(-4.2047577, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2559 \t Loss: tf.Tensor(-5.0535154, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2687 \t Loss: tf.Tensor(-5.083499, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2815 \t Loss: tf.Tensor(-5.16756, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2943 \t Loss: tf.Tensor(-5.149258, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3071 \t Loss: tf.Tensor(-4.970028, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3199 \t Loss: tf.Tensor(-4.8576226, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 127 \t Loss: tf.Tensor(-4.0478363, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 255 \t Loss: tf.Tensor(-3.681126, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 383 \t Loss: tf.Tensor(-4.2694273, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 511 \t Loss: tf.Tensor(-3.8584144, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 639 \t Loss: tf.Tensor(-3.0087621, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 767 \t Loss: tf.Tensor(-2.0631251, shape=(), dtype=float32)\n",
      "Epoch:  18\n",
      "TRAIN: \t cnt: 127 \t Loss: tf.Tensor(-2.6503866, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 255 \t Loss: tf.Tensor(-2.6621735, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: \t cnt: 383 \t Loss: tf.Tensor(-3.884914, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 511 \t Loss: tf.Tensor(-5.38912, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 639 \t Loss: tf.Tensor(-5.077876, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 767 \t Loss: tf.Tensor(-3.998054, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 895 \t Loss: tf.Tensor(-5.210382, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1023 \t Loss: tf.Tensor(-4.342013, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1151 \t Loss: tf.Tensor(-4.636067, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1279 \t Loss: tf.Tensor(-4.6089044, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1407 \t Loss: tf.Tensor(-4.558968, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1535 \t Loss: tf.Tensor(-5.1229124, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1663 \t Loss: tf.Tensor(-3.6481228, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1791 \t Loss: tf.Tensor(-3.939966, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1919 \t Loss: tf.Tensor(-5.3766026, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2047 \t Loss: tf.Tensor(-5.293609, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2175 \t Loss: tf.Tensor(-4.8570795, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2303 \t Loss: tf.Tensor(-5.3009815, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2431 \t Loss: tf.Tensor(-4.2170205, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2559 \t Loss: tf.Tensor(-5.0690017, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2687 \t Loss: tf.Tensor(-5.1037836, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2815 \t Loss: tf.Tensor(-5.1826363, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2943 \t Loss: tf.Tensor(-5.172228, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3071 \t Loss: tf.Tensor(-4.986984, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3199 \t Loss: tf.Tensor(-4.8779626, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 127 \t Loss: tf.Tensor(-4.0573626, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 255 \t Loss: tf.Tensor(-3.6877637, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 383 \t Loss: tf.Tensor(-4.2787924, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 511 \t Loss: tf.Tensor(-3.862039, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 639 \t Loss: tf.Tensor(-3.0041037, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 767 \t Loss: tf.Tensor(-2.0605822, shape=(), dtype=float32)\n",
      "Epoch:  19\n",
      "TRAIN: \t cnt: 127 \t Loss: tf.Tensor(-2.6459627, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 255 \t Loss: tf.Tensor(-2.6619554, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 383 \t Loss: tf.Tensor(-3.891388, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 511 \t Loss: tf.Tensor(-5.4086185, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 639 \t Loss: tf.Tensor(-5.095454, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 767 \t Loss: tf.Tensor(-4.0098925, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 895 \t Loss: tf.Tensor(-5.223072, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1023 \t Loss: tf.Tensor(-4.372213, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1151 \t Loss: tf.Tensor(-4.642038, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1279 \t Loss: tf.Tensor(-4.60858, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1407 \t Loss: tf.Tensor(-4.573528, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1535 \t Loss: tf.Tensor(-5.137503, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1663 \t Loss: tf.Tensor(-3.645044, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1791 \t Loss: tf.Tensor(-3.948441, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 1919 \t Loss: tf.Tensor(-5.396946, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2047 \t Loss: tf.Tensor(-5.310522, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2175 \t Loss: tf.Tensor(-4.8716183, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2303 \t Loss: tf.Tensor(-5.3158236, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2431 \t Loss: tf.Tensor(-4.229312, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2559 \t Loss: tf.Tensor(-5.083455, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2687 \t Loss: tf.Tensor(-5.1220045, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2815 \t Loss: tf.Tensor(-5.19661, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 2943 \t Loss: tf.Tensor(-5.1930847, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3071 \t Loss: tf.Tensor(-5.0030203, shape=(), dtype=float32)\n",
      "TRAIN: \t cnt: 3199 \t Loss: tf.Tensor(-4.8970966, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 127 \t Loss: tf.Tensor(-4.0672135, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 255 \t Loss: tf.Tensor(-3.6949878, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 383 \t Loss: tf.Tensor(-4.2877927, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 511 \t Loss: tf.Tensor(-3.866235, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 639 \t Loss: tf.Tensor(-3.0021365, shape=(), dtype=float32)\n",
      "VALID: \t cnt: 767 \t Loss: tf.Tensor(-2.0615861, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(args.num_epochs):\n",
    "    print(\"Epoch: \", epoch)\n",
    "    if epoch == 10:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "    \n",
    "    train(epoch, model, optimizer, loader_train)\n",
    "    train_loss.reset_states()\n",
    "    valid(epoch, model, loader_val)\n",
    "    valid_loss.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SnQ0Ij1SvU0E"
   },
   "source": [
    "## 6. Test\n",
    "### 6.1 Loading Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SbUls3qhvU0F",
    "outputId": "ed2c74b5-77f8-4a31-992d-9d06506d5803"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 818/818 [00:00<00:00, 10097.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Data .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dset_test = TrajectoryDataset(\n",
    "    data_set + 'test1/',\n",
    "    obs_len=obs_seq_len,\n",
    "    pred_len=pred_seq_len,\n",
    "    skip=1)\n",
    "\n",
    "loader_test = np.asarray(dset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s21rkqHcvU0F",
    "outputId": "cc7819bd-d39a-4ac8-986c-eeb2d1454a8e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/818 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 20\n",
      "**************************************************\n",
      "Testing ....\n",
      "WARNING:tensorflow:From E:\\Anaconda\\lib\\site-packages\\tensorflow_probability\\python\\distributions\\distribution.py:334: MultivariateNormalFullCovariance.__init__ (from tensorflow_probability.python.distributions.mvn_full_covariance) is deprecated and will be removed after 2019-12-01.\n",
      "Instructions for updating:\n",
      "`MultivariateNormalFullCovariance` is deprecated, use `MultivariateNormalTriL(loc=loc, scale_tril=tf.linalg.cholesky(covariance_matrix))` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 818/818 [14:22<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ade: 0.14121786136942202  fde: 0.24519761377462826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "KSTEPS = 20\n",
    "ade_ls = []\n",
    "fde_ls = []\n",
    "print('Number of samples:', KSTEPS)\n",
    "print(\"*\" * 50)\n",
    "\n",
    "obs_seq_len = args.obs_len\n",
    "pred_seq_len = args.pred_len\n",
    "data_set = './dataset/' + args.dataset + '/'\n",
    "\n",
    "ad_ = 999999\n",
    "fd_ = 999999\n",
    "print(\"Testing ....\")\n",
    "ade_,fde_,raw_data_dict = test(model, loader_test)\n",
    "ade_ = min(ade_, ad_)\n",
    "fde_ = min(fde_, fd_)\n",
    "ade_ls.append(ade_)\n",
    "fde_ls.append(fde_)\n",
    "print(\"ade:\", ade_, \" fde:\", fde_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Save Trojectory Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_result(model, loader_test, KSTEPS=20):\n",
    "    raw_data_dict = {}\n",
    "    ade_bigls = []\n",
    "    fde_bigls = []\n",
    "    pred_visual = []\n",
    "    tragets_visual = []\n",
    "\n",
    "    step =0\n",
    "    for batch in loader_test:\n",
    "        step += 1\n",
    "        \n",
    "        obs_traj, pred_traj_gt, obs_traj_rel, pred_traj_gt_rel, non_linear_ped, loss_mask, V_obs, V_tr = batch\n",
    "\n",
    "        V_obs = V_obs[np.newaxis, :]\n",
    "        V_tr = V_tr[np.newaxis, :]\n",
    "\n",
    "        identity_spatial = tf.ones((V_obs.shape[1], V_obs.shape[2], V_obs.shape[2])) * tf.eye(V_obs.shape[2])\n",
    "        identity_temporal = tf.ones((V_obs.shape[2], V_obs.shape[1], V_obs.shape[1])) * tf.eye(V_obs.shape[1])\n",
    "        identity = [identity_spatial, identity_temporal]\n",
    "        \n",
    "        V_pred = model(V_obs, identity)\n",
    "        V_tr = tf.cast(tf.squeeze(V_tr), dtype = tf.float32)\n",
    "        \n",
    "        num_of_objs = obs_traj_rel.shape[1]\n",
    "        V_pred, V_tr = V_pred[:, :num_of_objs, :], V_tr[:, :num_of_objs, :]\n",
    "        \n",
    "        sx = tf.math.exp(V_pred[:,:,2]) #sx\n",
    "        sy = tf.math.exp(V_pred[:,:,3]) #sy\n",
    "        corr = tf.math.tanh(V_pred[:,:,4]) #corr\n",
    "        \n",
    "        cov = np.zeros((V_pred.shape[0],V_pred.shape[1],2,2))\n",
    "        cov[:,:,0,0]= sx*sx\n",
    "        cov[:,:,0,1]= corr*sx*sy\n",
    "        cov[:,:,1,0]= corr*sx*sy\n",
    "        cov[:,:,1,1]= sy*sy\n",
    "        cov = tf.convert_to_tensor(cov, dtype=tf.float32)\n",
    "        mean = V_pred[:,:,0:2]\n",
    "        \n",
    "        mvnormal = tfp.distributions.MultivariateNormalFullCovariance(mean, cov)\n",
    "        \n",
    "        ade_ls = {}\n",
    "        fde_ls = {}\n",
    "        V_x = seq_to_nodes(tf.identity(obs_traj))\n",
    "        V_x_rel_to_abs = nodes_rel_to_nodes_abs(tf.identity(tf.squeeze(V_obs[:,:,:,:2])), tf.identity(V_x[0,:,:]))\n",
    "        V_y_rel_to_abs = nodes_rel_to_nodes_abs(tf.identity(tf.squeeze(V_tr)),tf.identity(V_x[-1,:,:]))\n",
    "        \n",
    "        raw_data_dict[step] = {}\n",
    "        raw_data_dict[step]['obs'] = copy.deepcopy(V_x_rel_to_abs)\n",
    "        raw_data_dict[step]['trgt'] = copy.deepcopy(V_y_rel_to_abs)\n",
    "        raw_data_dict[step]['pred'] = []\n",
    "        \n",
    "        for n in range(num_of_objs):\n",
    "            ade_ls[n]=[]\n",
    "            fde_ls[n]=[]\n",
    "        \n",
    "        for k in range(KSTEPS):\n",
    "\n",
    "            V_pred = mvnormal.sample()\n",
    "\n",
    "            V_pred_rel_to_abs = nodes_rel_to_nodes_abs(tf.identity(tf.squeeze(V_pred)), tf.identity(V_x[-1,:,:]))\n",
    "\n",
    "            raw_data_dict[step]['pred'].append(copy.deepcopy(V_pred_rel_to_abs))\n",
    "\n",
    "            for n in range(num_of_objs):\n",
    "                pred = []\n",
    "                target = []\n",
    "                obsrvs = []\n",
    "                number_of = []\n",
    "                pred.append(V_pred_rel_to_abs[:,n:n+1,:])\n",
    "                target.append(V_y_rel_to_abs[:,n:n+1,:])\n",
    "                obsrvs.append(V_x_rel_to_abs[:,n:n+1,:])\n",
    "                number_of.append(1)\n",
    "                \n",
    "                if n == 0:\n",
    "                    pred_visual.append(pred)\n",
    "                    tragets_visual.append(target)\n",
    "\n",
    "                ade_ls[n].append(ade(pred,target,number_of))\n",
    "                fde_ls[n].append(fde(pred,target,number_of))\n",
    "                   \n",
    "        for n in range(num_of_objs):\n",
    "            ade_bigls.append(min(ade_ls[n]))\n",
    "            fde_bigls.append(min(fde_ls[n]))\n",
    "\n",
    "    ade_ = sum(ade_bigls)/len(ade_bigls)\n",
    "    fde_ = sum(fde_bigls)/len(fde_bigls)\n",
    "    return ade_, fde_, raw_data_dict, pred_visual, tragets_visual\n",
    "\n",
    "def pre_and_result(pre_or_res = 0):\n",
    "    frame_id_x_y = []\n",
    "    for id, pedes in enumerate(zip(pred_visual, target_visual)):\n",
    "        id_x_y = []\n",
    "        frame_ids = []\n",
    "    #print(pedes[0])\n",
    "        frame_id = 0\n",
    "        for pre in pedes[pre_or_res][0]:\n",
    "      #print([item for item in pre])\n",
    "      #print(pre[0])\n",
    "            id_x_y.append([id+1, pre[0][0], pre[0][1]])\n",
    "            frame_ids.append(frame_id)\n",
    "            frame_id += 1\n",
    "    #print(dict(zip(frame_ids, id_x_y)))\n",
    "        frame_id_x_y.append(pd.DataFrame(dict(zip(frame_ids, id_x_y))))\n",
    "        id += 1\n",
    "    pre = frame_id_x_y[0]\n",
    "    for item in frame_id_x_y[1:]:\n",
    "        pre = pd.concat([pre, item], axis=1)\n",
    "    return pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predict trojectory\n",
    "_, _, _, pred_visual, target_visual = predict_result(model, loader_test)\n",
    "\n",
    "# Processing trojectory data\n",
    "pre = pre_and_result(0)\n",
    "res = pre_and_result(1)\n",
    "\n",
    "# Save data\n",
    "pre.to_csv('pre.csv')\n",
    "res.to_csv('res.csv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_new.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
